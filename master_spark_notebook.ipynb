{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import to_date, col\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "from pyspark.sql.functions import to_timestamp, date_format, hour, year, month, dayofmonth\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-39-2.us-west-2.compute.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=yarn appName=PySparkShell>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mongo Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Schema of the Green Taxi Database - data was cleaned in mongo:\n",
    "\n",
    "```\n",
    "s3cmd get s3://spark-proj/data/yellow_tripdata_2017-05.csv s3://spark-proj/data/yellow_tripdata_2017-04.csv s3://spark-proj/data/yellow_tripdata_2017-03.csv s3://spark-proj/data/yellow_tripdata_2017-02.csv s3://spark-proj/data/yellow_tripdata_2017-01.csv s3://spark-proj/data/yellow_tripdata_2016-12.csv s3://spark-proj/data/yellow_tripdata_2016-11.csv s3://spark-proj/data/yellow_tripdata_2016-10.csv s3://spark-proj/data/yellow_tripdata_2016-09.csv s3://spark-proj/data/yellow_tripdata_2016-08.csv s3://spark-proj/data/green_tripdata_2017-05.csv s3://spark-proj/data/green_tripdata_2017-04.csv s3://spark-proj/data/green_tripdata_2017-03.csv s3://spark-proj/data/green_tripdata_2017-02.csv s3://spark-proj/data/green_tripdata_2017-01.csv s3://spark-proj/data/green_tripdata_2016-12.csv s3://spark-proj/data/green_tripdata_2016-11.csv s3://spark-proj/data/green_tripdata_2016-10.csv s3://spark-proj/data/green_tripdata_2016-09.csv s3://spark-proj/data/green_tripdata_2016-08.csv\n",
    "\n",
    "mongoimport -d taxidb -c taxidata --type csv --headerline --file yellow_tripdata_2017-05.csv\n",
    "mongoimport -d taxidb -c taxidata --type csv --headerline --file yellow_tripdata_2017-04.csv\n",
    "mongoimport -d taxidb -c taxidata --type csv --headerline --file yellow_tripdata_2017-03.csv\n",
    "mongoimport -d taxidb -c taxidata --type csv --headerline --file yellow_tripdata_2017-02.csv\n",
    "mongoimport -d taxidb -c taxidata --type csv --headerline --file yellow_tripdata_2017-01.csv\n",
    "\n",
    "mongoimport -d taxidb -c taxidata --type csv --headerline --file green_tripdata_2017-05.csv\n",
    "mongoimport -d taxidb -c taxidata --type csv --headerline --file green_tripdata_2017-04.csv\n",
    "mongoimport -d taxidb -c taxidata --type csv --headerline --file green_tripdata_2017-03.csv\n",
    "mongoimport -d taxidb -c taxidata --type csv --headerline --file green_tripdata_2017-02.csv\n",
    "mongoimport -d taxidb -c taxidata --type csv --headerline --file green_tripdata_2017-01.csv\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Green Taxi Data from Mongo Database ( 1M total)\n",
    "\n",
    "Our data is currently stored in another EC2 database:\n",
    "\n",
    "`mongodb://ec2-54-190-6-201.us-west-2.compute.amazonaws.com/taxidb_sm.taxidata_g`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.145874977112\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "green_df = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\")\\\n",
    "    .option(\"uri\",\"mongodb://ec2-54-190-6-201.us-west-2.compute.amazonaws.com/taxidb_sm.taxidata_g\")\\\n",
    "    .load()\n",
    "print time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- _id: struct (nullable = true)\n",
      " |    |-- oid: string (nullable = true)\n",
      " |-- color: double (nullable = true)\n",
      " |-- ehail_fee: string (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- tpep_dropoff_datetime: string (nullable = true)\n",
      " |-- tpep_pickup_datetime: string (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- trip_type: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "green_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather Data ( per day per hour) - weather underground.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.135233163834\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "weather_df = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").option(\"uri\",\"mongodb://ec2-54-190-6-201.us-west-2.compute.amazonaws.com/taxidb.weather_data\").load()\n",
    "print time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def indexStringColumns(df, cols):\n",
    "    newdf = df\n",
    "    for c in cols:\n",
    "        si = StringIndexer(inputCol=c, outputCol=c+\"-num\")\n",
    "        sm = si.fit(newdf)\n",
    "        newdf = sm.transform(newdf).drop(c)\n",
    "        newdf = newdf.withColumnRenamed(c+\"-num\", c)\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_df = indexStringColumns(weather_df, ['condition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: struct (nullable = true)\n",
      " |    |-- oid: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- temp: double (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- condition: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yellow Taxi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.134047031403\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "yellow_df = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").option(\"uri\",\"mongodb://ec2-54-190-6-201.us-west-2.compute.amazonaws.com/taxidb_sm.taxidata_y\").load()\n",
    "print time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- _id: struct (nullable = true)\n",
      " |    |-- oid: string (nullable = true)\n",
      " |-- color: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- tpep_dropoff_datetime: string (nullable = true)\n",
      " |-- tpep_pickup_datetime: string (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yellow_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glue Yellow and Green Taxi data together for cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+----------+--------+-----+-----+-----------+---------------------+-------+---------------+------------+------------------+----------+------------+------------+---------------------+--------------------+-------------+\n",
      "|DOLocationID|PULocationID|RatecodeID|VendorID|color|extra|fare_amount|improvement_surcharge|mta_tax|passenger_count|payment_type|store_and_fwd_flag|tip_amount|tolls_amount|total_amount|tpep_dropoff_datetime|tpep_pickup_datetime|trip_distance|\n",
      "+------------+------------+----------+--------+-----+-----+-----------+---------------------+-------+---------------+------------+------------------+----------+------------+------------+---------------------+--------------------+-------------+\n",
      "|         113|         158|         1|       1|  1.0|  0.5|       10.5|                  0.3|    0.5|              1|           2|                 N|       0.0|         0.0|        11.8|  2017-04-01 00:15:07| 2017-04-01 00:00:00|          1.8|\n",
      "|         193|         264|         1|       2|  1.0|  0.0|        0.0|                  0.0|    0.0|              1|           1|                 N|       0.0|         0.0|         0.0|  2017-04-01 10:20:01| 2017-04-01 00:00:00|          0.0|\n",
      "+------------+------------+----------+--------+-----+-----+-----------+---------------------+-------+---------------+------------+------------------+----------+------------+------------+---------------------+--------------------+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "select_cols = [x for x in yellow_df.columns if x!='_id' ]\n",
    "\n",
    "y_df = yellow_df.select(select_cols)\n",
    "y_df = y_df.sample(False,0.2, seed=1)\n",
    "y_df.cache()\n",
    "\n",
    "g_df = green_df.select(select_cols)\n",
    "g_df = g_df.sample(False,0.1, seed=1)\n",
    "g_df.cache()\n",
    "\n",
    "total_df = y_df.unionAll(g_df)\n",
    "total_df.cache()\n",
    "total_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering - extracting data from dates\n",
    "\n",
    "- Day of Week\n",
    "- Day of Month\n",
    "- Month\n",
    "- Round to hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_dates(df, colName, newCol):\n",
    "    return df.withColumn(newCol,to_timestamp(colName, 'yyyy-MM-dd HH:mm:ss')).drop(colName)\n",
    "\n",
    "def get_dateinfo(df, colName):\n",
    "    return df.withColumn('dow', date_format(colName,'u').cast(IntegerType()))\\\n",
    "    .withColumn('hour', hour(colName))\\\n",
    "    .withColumn('day', dayofmonth(colName))\\\n",
    "    .withColumn('month', month(colName))\\\n",
    "    .withColumn('year', year(colName))\n",
    "    \n",
    "def indexStringColumns(df, cols):\n",
    "    newdf = df\n",
    "    for c in cols:\n",
    "        si = StringIndexer(inputCol=c, outputCol=c+\"-num\")\n",
    "        sm = si.fit(newdf)\n",
    "        newdf = sm.transform(newdf).drop(c)\n",
    "        newdf = newdf.withColumnRenamed(c+\"-num\", c)\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean the total dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.8021991253\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "df_dates = make_dates(total_df, \"tpep_dropoff_datetime\", \"dropoff_datetime\")\n",
    "df_dates = make_dates(df_dates, \"tpep_pickup_datetime\", \"pickup_datetime\")\n",
    "new_df = indexStringColumns(df_dates, [\"store_and_fwd_flag\"])\n",
    "new_df = get_dateinfo(df_dates, 'dropoff_datetime')\n",
    "print time.time() - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join in the weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joined_df = new_df.join(w_df,[new_df.day==w_df.day, new_df.month==w_df.month, new_df.hour==w_df.hour], 'left_outer')\n",
    "joined_df = joined_df.select(new_df.DOLocationID, new_df.PULocationID, new_df.RatecodeID, new_df.VendorID, new_df.color, new_df.extra, new_df.fare_amount, new_df.improvement_surcharge, new_df.mta_tax, new_df.passenger_count, new_df.payment_type, new_df.store_and_fwd_flag, new_df.tip_amount, new_df.tolls_amount, new_df.total_amount, new_df.trip_distance, new_df.dropoff_datetime, new_df.pickup_datetime, new_df.dow, new_df.hour, new_df.day, new_df.month, new_df.year, w_df.temp, w_df.condition)\n",
    "joined_df = joined_df.drop(\"dropoff_datetime\").drop(\"pickup_datetime\").drop(\"store_and_fwd_flag\").drop(\"ehail_fee\").drop(\"trip_type\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot Encode any of the categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- color: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- dow: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- temp: double (nullable = true)\n",
      " |-- condition: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- temp: double (nullable = true)\n",
      " |-- DOLocationID: vector (nullable = true)\n",
      " |-- PULocationID: vector (nullable = true)\n",
      " |-- RatecodeID: vector (nullable = true)\n",
      " |-- VendorID: vector (nullable = true)\n",
      " |-- condition: vector (nullable = true)\n",
      " |-- dow: vector (nullable = true)\n",
      " |-- day: vector (nullable = true)\n",
      " |-- month: vector (nullable = true)\n",
      "\n",
      "20.3193440437\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "\n",
    "def oneHotEncodeColumns(df, cols):\n",
    "    newdf = df\n",
    "    for c in cols:\n",
    "        #For each given colum, create OneHotEncoder. \n",
    "        #dropLast : Whether to drop the last category in the encoded vector (default: true)\n",
    "        onehotenc = OneHotEncoder(inputCol=c, outputCol=c+\"-onehot\", dropLast=False)\n",
    "        #Creates a DataFame by putting the transformed values in the new colum with suffix \"-onehot\" \n",
    "        #and then drops the original columns.\n",
    "        #and drop the \"-onehot\" suffix. \n",
    "        newdf = onehotenc.transform(newdf).drop(c)\n",
    "        newdf = newdf.withColumnRenamed(c+\"-onehot\", c)\n",
    "    return newdf\n",
    "\n",
    "onehot_cols = [ x for x in joined_df.columns if 'ID' in x]\n",
    "onehot_cols = onehot_cols + ['condition', 'dow','day','month']\n",
    "\n",
    "joined_df.printSchema()\n",
    "dfhot = oneHotEncodeColumns(joined_df,onehot_cols)\n",
    "df_for_model = dfhot.withColumnRenamed(\"color\",\"label\")\n",
    "df_for_model.printSchema()\n",
    "\n",
    "print time.time() - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Vectors for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "va = VectorAssembler(outputCol=\"features\", inputCols=df_for_model.drop(\"label\").columns) #except the last col.\n",
    "taxi_points = va.transform(df_for_model).select(\"features\", \"label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split_data = taxi_points.randomSplit([0.8, 0.2])\n",
    "training = split_data[0].cache()\n",
    "test = split_data[1].cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3M : 217.947538137\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217.947538137\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "rf = RandomForestClassifier(maxDepth=20)\n",
    "rfmodel = rf.fit(training)\n",
    "print time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.0477124\n",
      "30.1611700058\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "rfpredicts = rfmodel.transform(test)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(rfpredicts)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "print time.time() - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tip_amount', 0.020473327717663619),\n",
       " ('trip_distance', 0.015715295457191372),\n",
       " ('improvement_surcharge', 0.015558255022715064),\n",
       " ('fare_amount', 0.01521496550253601),\n",
       " ('total_amount', 0.015137444771896458),\n",
       " ('hour', 0.0099468248971165685),\n",
       " ('passenger_count', 0.0084854350164258272),\n",
       " ('month', 0.0052412768762240877),\n",
       " ('payment_type', 0.0039374205747062709),\n",
       " ('extra', 0.003339054355755852),\n",
       " ('temp', 0.0028635818705883618),\n",
       " ('tolls_amount', 0.0013714347684928045),\n",
       " ('mta_tax', 0.0011805397472915171),\n",
       " ('condition', 4.3180992096275849e-05),\n",
       " ('PULocationID', 2.3114616875778983e-05),\n",
       " ('VendorID', 3.3505529096956143e-06),\n",
       " ('day', 1.2891682775805025e-06),\n",
       " ('DOLocationID', 0.0),\n",
       " ('year', 0.0),\n",
       " ('RatecodeID', 0.0),\n",
       " ('dow', 0.0)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "columns = df_for_model.drop(\"label\").columns\n",
    "importances = {}\n",
    "for score,col in zip(rfmodel.featureImportances, columns):\n",
    "    importances[col] =  score\n",
    "sorted_importances = sorted(importances.items(), key=operator.itemgetter(1), reverse = True)\n",
    "sorted_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "logreg = LogisticRegression()\n",
    "log_model = logreg.fit(training)\n",
    "print time.time() - start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "logpredicts = log_model.transform(test)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(logpredicts)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "print time.time() - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
